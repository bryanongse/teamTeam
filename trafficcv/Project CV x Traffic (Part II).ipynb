{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Huz1bj_m53c"
   },
   "source": [
    "# Introduction\n",
    "<font color='orange'>[Google Colab]</font> In Part I, we explored the traffic image API and mapped out the locations of the cameras in the country.\n",
    "\n",
    "We then acquired images from a few traffic cameras for inspection.\n",
    "\n",
    "In this Part, this is what you'll do:\n",
    "1. Import libraries\n",
    "2. Collect two years' worth of traffic image JSON\n",
    "3. Combine the eventual DataFrame\n",
    "4. Filter for camera ID 1709 only\n",
    "5. Export DataFrame for Part III\n",
    "\n",
    "<strong>Apart from coding, data collection alone will take <font color='red'>2 hours or so</font>. Make sure you allocate plenty of time for this Part.</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9M32NHm5oCW9"
   },
   "source": [
    "### Step 1: Import libraries\n",
    "We'll start off with importing the libraries that we need:\n",
    "- requests\n",
    "- pandas as pd\n",
    "- datetime\n",
    "- time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7F3l9pilg3w"
   },
   "outputs": [],
   "source": [
    "# Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXhp0aBMWpZ9"
   },
   "source": [
    "# Testing collection\n",
    "Before we collect data en masse, we should collect the data bit by bit first and measure the time taken to assess the right strategy.\n",
    "\n",
    "We'll start by making simple class first, then building up for more while keeping an expectation of how much time these tasks will take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zI19hTpTC1p"
   },
   "source": [
    "### Step 2: Create a range of dates and time\n",
    "We'll be retrieving a day's worth of data first, with an interval of 1 minute. \n",
    "\n",
    "We do that because the API documentation recommends so. Use pandas' date range to get a range of time between \"2019/01/01\" and \"2019/01/02\", with a frequency of 1 minute.\n",
    "\n",
    "![DataRangeExample](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectComputerVisionTraffic/DataRangeOneDay.png)\n",
    "\n",
    "Your list will be 1,441 items long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LAvRp3dQyIzz",
    "outputId": "f13790f7-f1ab-48de-949f-28e7c1396212"
   },
   "outputs": [],
   "source": [
    "# Step 2: Get a range of dates and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lka9LXpPXMP0",
    "outputId": "6cb52203-300a-4502-c2f0-19eb50724834"
   },
   "outputs": [],
   "source": [
    "# Optional: Check length of list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXBbyagoiiU4"
   },
   "source": [
    "### Step 3: Format the datetime into a string\n",
    "Now that you have a list of datetime items, you'll have to structure them into the right format that you can use. \n",
    "\n",
    "You'll have to call the strftime method, along with the right format to format the eventual string output.\n",
    "\n",
    "In this Step, try to print a string from the first datetime in the list.\n",
    "\n",
    "```\n",
    "2019-01-01 00:00:00 \n",
    "\n",
    "to \n",
    "\n",
    "2019-01-01T00%3A00%3A00\n",
    "```\n",
    "\n",
    "Something like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "3Mreid_Vy6aJ",
    "outputId": "d2d12bc8-dac5-466e-8991-66b340b6c2c8"
   },
   "outputs": [],
   "source": [
    "# Step 3: Format the first datetime in list to string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2dLwUQ9orHl"
   },
   "source": [
    "### Step 4: Call API for the list of datetimes\n",
    "Now that you've figured out how to format the datetime into a string, it's time to loop through them and make repeated calls and store the JSON responses in a list.\n",
    "\n",
    "You should use the <strong>time</strong> library to measure how long it takes to call the API to get the all 1,441 times.\n",
    "\n",
    "You should end up with a list containing 1,441 JSON objects.\n",
    "\n",
    "<font color = 'red'>Allocate 30-40 minutes for this task.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynMmWd3LsZ04"
   },
   "source": [
    "<details>\n",
    "  <summary>Click here once if you're unsure and need pseudocode</summary>\n",
    "  <ol>\n",
    "    <li>Declare a variable containing an empty list</li>\n",
    "    <li>Declare a variable containing a base URL for the API</li>\n",
    "    <li>Use a for loop for the list you got from Step 3. In each loop:</li>\n",
    "    <ol>\n",
    "      <li>Declare a temporary URL consisting of the base URL and the current datetime in list</li>\n",
    "      <li>Make a GET request using the URL and store the response in a variable</li>\n",
    "      <li>Perform a .json method and store the JSON object in a new variable</li>\n",
    "      <li>Append the variable into the list the you declared earlier</li>\n",
    "    </ol>\n",
    "  </ol>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_lfzcqQ2zjOx",
    "outputId": "95439488-39b9-4173-9d05-ad550d9239a3"
   },
   "outputs": [],
   "source": [
    "# Step 4: Call API and get a list of JSON objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "golFFvk0EQyB"
   },
   "source": [
    "### Step 5: Combine all the JSON into a DataFrame\n",
    "With your list of JSON objects, turn each of them into DataFrame and append them in another list. \n",
    "\n",
    "![ConcatenatedDataFrameOneDay](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectComputerVisionTraffic/ConcatenatedDataFrameOneDay.png)\n",
    "\n",
    "With the list of DataFrames, concatenate them so that they'll end up as a single DataFrame.\n",
    "\n",
    "You are anticipating:\n",
    "- 124,874 rows\n",
    "- 8 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "0Su86arGIpoM",
    "outputId": "a81485e7-bd70-451d-ea9f-3027bd81318d"
   },
   "outputs": [],
   "source": [
    "# Step 5: Combine the list of JSON into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SarDVy-7kx8q"
   },
   "source": [
    "### Step 6: Filter the DataFrame for camera 1709 only\n",
    "Your huge DataFrame currently contains the URLs for the images from ALL cameras in a single day.\n",
    "\n",
    "Filter the DataFrame to contain only rows from <strong>camera_id = 1709</strong> so we can see how many rows there are in a single day. \n",
    "\n",
    "We should expect:\n",
    "- 1441 rows\n",
    "- 8 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "fHScDp0EKh-2",
    "outputId": "fdc75bbe-9088-4e5a-dc37-1c9a42566a55"
   },
   "outputs": [],
   "source": [
    "# Step 6: Filter for 1709"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTO95433mBfx"
   },
   "source": [
    "### Step 7: Drop duplicates based on 'image'\n",
    "If you observe carefully, there are some rows that are repeated.\n",
    "\n",
    "Drop duplicates by 'image' column and see how many rows you end up with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "612O6X-XLAbW",
    "outputId": "a21dd851-6896-4ce0-f7b5-1d59a7a19d31"
   },
   "outputs": [],
   "source": [
    "# Step 7: Drop duplicates by 'image' column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXQIJRwGodpC"
   },
   "source": [
    "# Full data collection\n",
    "Now that we have figured out how to collect one day's worth of data, we can now collect two one-month data:\n",
    "- 2019/01/01 to 2019/02/01\n",
    "- 2020/01/01 to 2020/01/01\n",
    "\n",
    "Wait a minute. Do you notice something is off?\n",
    "\n",
    "<details>\n",
    "  <summary>Click here to check if your guess is right</summary>\n",
    "  <p><strong>If doing one day's worth of API calling took 30 minutes, doing 2 months' worth of API calling means it will take 30 mins per day's JSON x 30 days per month x 2 months = 1800 minutes.</strong></p>\n",
    "  <p><strong>That's 30 hours!</strong></p>\n",
    "</details>\n",
    "\n",
    "Don't worry - we'll be using multithreading to make multiple calls at the same time.\n",
    "\n",
    "Reading: https://docs.python.org/3/library/concurrent.futures.html (scroll to ThreadPoolExecutor Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zxgtYMauShi"
   },
   "source": [
    "### Step 8: Set up date_ranges\n",
    "Let's just set up the range of dates we need to collect data on.\n",
    "\n",
    "Declare two variables containing the two date ranges we want, in minute frequency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yUd8XpQyPEEB",
    "outputId": "69615012-2894-4091-cff9-b14e5843a886"
   },
   "outputs": [],
   "source": [
    "# Step 8a: Set up date range for 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxidBAYJunpW",
    "outputId": "4667f8c4-e1a2-4da3-e40b-109b57770a40"
   },
   "outputs": [],
   "source": [
    "# Step 8b: Set up date range for 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IDljk0Eu1HJ"
   },
   "source": [
    "### Step 9: Define retrieveCameraJSON\n",
    "Define a function nalled retrieveCameraJSON where it takes in one argument - url.\n",
    "\n",
    "This function will return one JSON from one URL. \n",
    "\n",
    "In short, it's doing what you did in Step 4 but no for loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ykS0LeoxFbO"
   },
   "source": [
    "<details>\n",
    "<summary>Click here for pseudocode if you need help</summary>\n",
    "  <ol>\n",
    "    <li><strong>Define</strong> retrieveCameraJSON, taking in one argument called date_time</li>\n",
    "    <li>In the function definition</li>\n",
    "    <ul>\n",
    "    <li>Declare a variable that contains the base URL, just before date_time=</li>\n",
    "    <li>Declare a variable that takes the base URL and combines it with the formatted date_time argument (refer to Step 3)</li>\n",
    "    <li>Make a GET request to get the response of the API call</li>\n",
    "    <li>Declare a varible to store the JSON data of the response</li>\n",
    "    <li><strong>Return</strong> the variable</li>\n",
    "    </ul>\n",
    "  </ol>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Txp9ut7dHZx6"
   },
   "outputs": [],
   "source": [
    "# Step 9: Define retrieveCameraJSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKrgot170nG_"
   },
   "source": [
    "### Step 10: Import library\n",
    "Since we're doing concurrency, we'll need:\n",
    "- futures from concurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13CFtYno0xCc"
   },
   "outputs": [],
   "source": [
    "# Step 10: Import futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKD_Hwb-00jk"
   },
   "source": [
    "### Step 11: Use concurrency to retrieve JSON data from 2019\n",
    "Now that we have defind retrieveCameraJSON, let's make our API calls.\n",
    "\n",
    "With reference to the <a href=\"https://docs.python.org/3/library/concurrent.futures.html\">reading</a> provided above, you'll make lots of requests concurrently.\n",
    "\n",
    "If this is the first time doing a concurrency call, don't worry - try:\n",
    "1. Small number of rows to see if you got it right\n",
    "2. Adapting the code from the reading\n",
    "\n",
    "<font color='red'><strong>Reserve around 60 minutes for this Step.</strong></font>\n",
    "\n",
    "<details>\n",
    "<summary>Click here once for the pseudocode if you're stuck</summary>\n",
    "  <ol>\n",
    "    <li>Declare an empty list to store the <strong>.result</strong> of your completed futures</li>\n",
    "    <li>Use a <strong>with</strong> statement with futures.ThreadPoolExecutor, with a max_workers of 150 as an <strong>executor</strong></li>\n",
    "    <li>Declare a variable, where it is a list containing the the futures of retrieveCameraJSON with the date <strong>for</strong> the date in the date range in 2019</li> \n",
    "    <li>Use a <strong>for</strong> loop for the .as_completed list of futures</li>\n",
    "    <ul>\n",
    "      <li>Append the .result() of each future in the list to the list that you declared at the top</li>\n",
    "    </ul>\n",
    "  </ol>\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "    <summary><font color = 'green'>SPOILERS! Click once for a redacted code block if you're really really really stuck.</font></summary>\n",
    "    <div>\n",
    "        <img src = 'https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectComputerVisionTraffic/ConcurrentFunctionCalls.png'>\n",
    "    </div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nk-DGdu7HlQw",
    "outputId": "c463770f-d487-4365-ab6a-bb85b4578eb7"
   },
   "outputs": [],
   "source": [
    "# Step 11a: Make concurrent API calls for 2019 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPVAyBXG4bki"
   },
   "outputs": [],
   "source": [
    "# Step 11b: Get length of list of JSON results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZoutv0N4ITf"
   },
   "source": [
    "### Step 12: Repeat Step 5-7 to get 2019 Jan DataFrame\n",
    "Now that you have a long list of JSON objects, it's time to turn them into a DataFrame. \n",
    "\n",
    "Repeat what you did earlier and get a huge DataFrame containing traffic image URLs for 2019 Jan.\n",
    "\n",
    "You should expect around <strong>30,000 rows<strong> after dropping duplicates and filtering for 1709 in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xyhez7fK4-BQ"
   },
   "outputs": [],
   "source": [
    "# Step 12: Get the 2019 Jan DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_pzbj7q5Dkk"
   },
   "source": [
    "### Step 13: Sort the DataFrame by timestamp\n",
    "Using concurrency meant that the JSON in the list is not ordered chronologically.\n",
    "\n",
    "As such, you'll have to sort the DataFrame by timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gp3eL50E5DBs"
   },
   "outputs": [],
   "source": [
    "# Step 13: Sort the DataFrame by timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RuuDJ6AhwoFs"
   },
   "source": [
    "### Step 14: Export the DataFrame into a CSV file\n",
    "Once you're done with sorting, export your hard work into a CSV file in your Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyIH5sa8wx-g"
   },
   "outputs": [],
   "source": [
    "# Step 14: Export the DataFrame into CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sa9clCYI38Up"
   },
   "source": [
    "### Step 15: Repeat Steps 11-14 for date range in 2020\n",
    "Now that you're done with 2019, time to collect data for 2020 Jan.\n",
    "\n",
    "Make the same concurrenct calls but with the 2020 date range that you set up earlier.\n",
    "\n",
    "You might get a different number depending on the API's behaviour, but expect around 29,900 rows at the end after removing duplicate entries.\n",
    "\n",
    "<font color='red'><strong>Allocate another hour for this Step.</strong></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u11eD7LSXOw4"
   },
   "outputs": [],
   "source": [
    "# Step 15: Repeat Steps 11-14 for 2020 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Mv29rk_4etx"
   },
   "source": [
    "# End of Part II\n",
    "What a long Part. In this Part, you successfully made multiple API calls and obtained two months' worth of data.  \n",
    "\n",
    "Next Part, we will retrieve the images from the URL we find in the DataFrame for both years. We will also prepare for setting up Google Colab for object detection with GPU.\n",
    "\n",
    "The next part is quite long as well so prepare yourself."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project CV x Traffic (Part II)",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
